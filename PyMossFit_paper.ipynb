{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10362993,
          "sourceType": "datasetVersion",
          "datasetId": 6418267
        },
        {
          "sourceId": 10367407,
          "sourceType": "datasetVersion",
          "datasetId": 6421356
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "PyMossFit",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fsacconeUBA/PyMossFit/blob/paper/PyMossFit_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "fabiodanielsaccone_iguazu_sample_path = kagglehub.dataset_download('fabiodanielsaccone/iguazu-sample')\n",
        "fabiodanielsaccone_opportunity_path = kagglehub.dataset_download('fabiodanielsaccone/opportunity')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtqpwu0S6CVc",
        "outputId": "8b606c9b-ccd8-4cce-8de8-ec7907f559a5"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/fabiodanielsaccone/iguazu-sample?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68.5k/68.5k [00:00<00:00, 31.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/fabiodanielsaccone/opportunity?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58.4k/58.4k [00:00<00:00, 31.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Data source import complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyMossFit: A Google Colab option for Mössbauer Spectra Fitting\n",
        "\n",
        "# Introduction\n",
        "Mössbauer spectroscopy is a highly specialized technique that investigates the resonant absorption of gamma rays by atomic nuclei. The Mössbauer effect, observed primarily in isotopes like iron-57 ($^{57}Fe$), provides insight into hyperfine interactions, including isomer shifts, quadrupole splittings, and magnetic hyperfine fields. These parameters offer detailed information about the electronic, magnetic, and structural environment of the sample, making the technique invaluable in material science, chemistry, and condensed matter physics. The gamma ray of resonant absorption in $^{57}Fe$ nuclei is *14.4 keV*\n",
        "\n",
        "In a typical Mössbauer experiment, a radioactive source emits gamma rays, which are absorbed by the nuclei in the sample. Resonant absorption occurs, in a small fraction, when gamma rays hit the probe with recoil less. The detector measures the intensity of the transmitted radiation as a function of the velocity of the gamma-ray source. This results in a Mössbauer spectrum, typically characterized by sharp peaks or dips at resonance frequencies, corresponding to different hyperfine interactions within the sample. The most common experimental setup corresponds to *Transmission Geometry* (in this case, the observed lines come from a reduction of *14.4 keV* gamma counting in detector, as compared to the background signal). Other option is the *Conversion Electron Mössbauer Spectroscopy (CEMS)* that correspond to detection of back scattered electrons after gamma absorption.\n",
        "\n",
        "Recently, in a review written by Grandjean et al [[Grandjean2021]](https://doi.org/10.1021/acs.chemmater.1c00326),the authors made a series of suggestion about how good measurements should be taken and which could be a good practice for Mössbauer data treatment and its corresponding fitting presentation.\n",
        "\n",
        "In this sense, Google Colab is a useful tool for a colaborative team job in data analysis with the aditional advantage of no aditional packages locally installed, also compatible with the fact that the user can run their codes from multiple devices.\n",
        "\n",
        "# Mössbauer Spectra and Curve Shapes\n",
        "The shape of a Mössbauer spectrum varies depending on the nature of the hyperfine interactions in the sample. For example, a simple paramagnetic material might produce a single absorption peak (Lorentzian, Gaussian  or PseudoVoigt) due to the isomer shift. Materials with quadrupole splitting generate a doublet (two peaks), while materials experiencing magnetic hyperfine interactions often exhibit more complex sextet patterns. These spectral features often overlap, making it challenging to isolate and quantify each component manually.\n",
        "\n",
        "Curve fitting plays a crucial role in Mössbauer spectral analysis, as it allows for the decomposition of these complex spectra into individual contributions, each associated with specific hyperfine parameters. The challenge lies in accurately reproducing the spectral shapes using mathematical models and adjusting the parameters until a satisfactory fit is achieved.\n",
        "\n",
        "# Curve Fitting and Least Squares Method\n",
        "To accurately extract physical parameters from Mössbauer spectra, fitting procedures are applied to the experimental data. One of the most common approaches is the *least-squares method*, which minimizes the difference between the experimental data points and the theoretical model curve. The objective is to adjust the parameters of the theoretical model (such as isomer shift, quadrupole splitting, and line broadening) so that the calculated spectrum fits the experimental data as closely as possible. Then, it is required a minimization of the $\\chi^2$, defined as:\n",
        "\n",
        "$$\\chi^2=\\sum_{i=1}^{N}\\frac{(y_i^{exp}-y_i^{model}(\\vec{p}))^2}{\\epsilon_i^2}$$\n",
        "\n",
        "In Python, this process can be implemented using libraries like *Lmfit*, *SciPy*, or *NumPy*, which provide robust tools for least-squares curve fitting. The general approach involves defining a model function that represents the expected shape of the Mössbauer spectrum, which could be a sum of multiple Lorentzian or Gaussian functions, depending on the number and type of spectral components. Lorentzian functions are preferred with crystalline samples, while PseudoVoigts (sum of Lorentzian and Gaussian functions) are appropriated for Fe sites in disordered materials. The least-squares fitting algorithm iteratively adjusts the parameters of the model until the sum of squared residuals between the experimental and calculated spectra is minimized.\n",
        "\n",
        "# Description of the Python code for Google Colab (PyMossFit)\n",
        "The Python code is available in several Jupyter notebooks as typical examples found in practice. Some selected parts of it are described througout this page.\n",
        "[[Saccone2024a]](https://github.com/fsacconeUBA/Mossbauer/releases/tag/PyMossFit-V3)[[Saccone2024b]](http://dx.doi.org/10.13140/RG.2.2.20717.81127). (The comments and code section headings are in spanish)\n",
        "\n",
        "The code is structured in three cells. The first one includes the installation of *Lmfit*, the core of data fitting. Also, it imports some packages of *Scipy*, *Pandas*, *Matplotlib* and *Numpy*, among others. The next step, includes a Drive connection which asks permission to user."
      ],
      "metadata": {
        "id": "5qGQZbgl6CVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmfit\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount= True)\n",
        "img = '/content/drive/MyDrive/Colab Notebooks/My Directory/My File'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from lmfit import Parameters, minimize, fit_report\n",
        "from scipy.constants import *\n",
        "from scipy.integrate import trapz\n",
        "from scipy.signal import savgol_filter\n",
        "from pathlib import Path\n",
        "\n",
        "path= Path(img); name= path.stem; title= path.parent.name; full= path.parents[0]; print(name, title, full)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T01:19:11.519319Z",
          "iopub.execute_input": "2024-10-24T01:19:11.519784Z",
          "iopub.status.idle": "2024-10-24T01:19:25.83547Z",
          "shell.execute_reply.started": "2024-10-24T01:19:11.519739Z",
          "shell.execute_reply": "2024-10-24T01:19:25.83363Z"
        },
        "_kg_hide-output": true,
        "trusted": true,
        "id": "XZi7QGgs6CVw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second cell, reads the datafile (format should be inspected previously to define \"delimiter\", \"columns\" and \"skiprows\" parameters). The required inputs are date (in a YYYYMMDD format) and maximum velocity asociated to the extreme channels.\n",
        "In this cell, the spectrum folding is performed with a Discrete Fourier Transforming routine, the Numpy fft. The theory of this procedure corresponds to the Nyquist-Shannon Sampling Theorem that helps to determine a folding channel from the symmetry of Discrete Fourier spectra [[Kong2020]](https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.02-Discrete-Fourier-Transform.html). Also data can be smoothed by means of a Savitsky-Golay package (I use savgol from Scipy). After folding, a new datafile is saved for fitting with the use of the next cell."
      ],
      "metadata": {
        "id": "XRDHMT1T6CV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of the output plot, before and after folding, is shown below (Sample corresponds to an iron-zinc mixed ferrites [[Ferrari2015]](http://dx.doi.org/10.1109/TMAG.2014.2377132).\n",
        "\n",
        "![imagen.png](attachment:b90bc39b-8d8e-4c8a-9135-8672b4529ac9.png)\n",
        "\n",
        "![imagen.png](attachment:96e9ca11-185c-4bc5-b1ff-beb12d24fe79.png)"
      ],
      "metadata": {
        "id": "kiwxpP0O6CV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last cell performs the fitting procedure, gives a statistical report and shows in plot the original data and the fitting model. The functions for fitting are defined as follows (doublet_v and sextet_v stands for PseudoVoigt functions):"
      ],
      "metadata": {
        "id": "OseaocK46CWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singlet(a, b, m, x):\n",
        "    return 2*a*b/(pi*(b**2+4*(x-m)**2))\n",
        "\n",
        "def doublet(a, b, m, d, x):\n",
        "    return 2*a*b/(pi*(b**2+4*(x-(m-d/2))**2))+2*a*b/(pi*(b**2+4*(x-(m+d/2))**2))\n",
        "\n",
        "def sextet(a, b, m, d, q, l23, x):\n",
        "    return 3*a*b/(pi*(b**2+4*(x-(m+5*d))**2))+l23*a*b/(pi*(b**2+4*(x-(m+3*d-q))**2))+a*b/(pi*(b**2+4*(x-(m+d))**2))+a*b/(pi*(b**2+4*(x-(m-d))**2))+l23*a*b/(pi*(b**2+4*(x-(m-3*d+q))**2))+3*a*b/(pi*(b**2+4*(x-(m-5*d))**2))\n",
        "\n",
        "def doublet_v(av, mv, bl, bg, dl, dg, x):\n",
        "      return 2*av*bl/pi*(bl**2+(4*(x-(mv-dl/2))**2))+2*av*bl/pi*(bl**2+(4*(x-(mv+dl/2))**2))+(1-av)*np.exp(-(x-(mv-dg/2))**2/(2*bg**2))/(bg*np.sqrt(2*np.pi))+(1-av)*np.exp(-(x-(mv+dg/2))**2/(2*bg**2))/(bg*np.sqrt(2*np.pi))\n",
        "\n",
        "def sextet_v(a, b, m, d, q, l23, x):\n",
        "    return 3*a*(b/(pi*(b**2+4*(x-(m+5*d))**2))+np.exp(-(x-(m+5*d))**2/(2*b**2))/(b*np.sqrt(2*pi)))+l23 *a*(b/(pi*(b**2+4*(x-(m+3*d-q))**2))+np.exp(-(x-(m+3*d-q))**2/(2*b**2))/(b*np.sqrt(2*pi)))+a*(b/(pi*(b**2+4*(x-(m+d))**2))+np.exp(-(x-(m+d))**2/(2*b**2))/(b*np.sqrt(2*pi)))+a*(b/(pi*(b**2+4*(x-(m-d))**2))+np.exp(-(x-(m-d))**2/(2*b**2))/(b*np.sqrt(2*pi)))+l23*a*(b/(pi*(b**2+4*(x-(m-3*d+q))**2))+np.exp(-(x-(m-3*d+q))**2/(2*b**2))/(b*np.sqrt(2*pi)))+3*a*(b/(pi*(b**2+4*(x-(m-5*d))**2)+np.exp(-(x-(m-5*d))**2)/(2*b**2))/(b*np.sqrt(2*pi)))\n",
        "\n",
        "def linear_fitting_lmfit(params, x, y):\n",
        "    b1= params['b1']; m1= params['m1']; d1= params['d1']; a1= params['a1']\n",
        "    a2= params['a2']; b2= params['b2']; m2= params['m2']; d2= params['d2']; q2= params['q2']; l232= params['l232']\n",
        "    a3= params['a3']; b3= params['b3']; m3= params['m3']; d3= params['d3']; q3= params['q3']; l233= params['l233']\n",
        "    a4= params['a4']; b4= params['b4']; m4= params['m4']; d4= params['d4']\n",
        "\n",
        "    y_fit= 1-(doublet(a1, b1, m1, d1, x))-(sextet(a2, b2, m2, d2, q2, l232, x))-(sextet(a3, b3, m3, d3, q3, l233, x))-doublet(a4, b4, m4, d4, x)\n",
        "\n",
        "    return y_fit-y"
      ],
      "metadata": {
        "id": "wzS5K4Ui6CWE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The set of parameters such as linewidth, isomer shifts, quadrupole splitting and hyperfine field are calculated after adjusting the amplitud (*a*), full width at half maximum (*b*), centroid (*m*), line shift (*d*) and line separation (*q*). Initial set of these parameters can be fitted or fixed by selecting the *\"True*\" or *\"False\"* options, respectively. A typical fit report of the output of this cell looks as following:\n"
      ],
      "metadata": {
        "id": "HjBE5Cxl6CWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ancho (sigma/sqrt(2)) es: 0.24 mm/s\n",
        "Centroide (ISO1) es: 1.066 mm/s\n",
        "Amplitud (a) es: 0.0621\n",
        "Doblete es: 2.896 mm/s\n",
        "área: 100.0 %\n",
        "[[Fit Statistics]]\n",
        "    # fitting method   = least_squares\n",
        "    # function evals   = 35\n",
        "    # data points      = 255\n",
        "    # variables        = 4\n",
        "    chi-square         = 2.8129e-04\n",
        "    reduced chi-square = 1.1207e-06\n",
        "    Akaike info crit   = -3489.93535\n",
        "    Bayesian info crit = -3475.77029\n",
        "[[Variables]]\n",
        "    b:  0.33342395 +/- 0.00174860 (0.52%) (init = 0.3)\n",
        "    m:  1.06583140 +/- 6.2960e-04 (0.06%) (init = 1)\n",
        "    d:  2.89583004 +/- 0.00125858 (0.04%) (init = 2.9)\n",
        "    a:  0.06212909 +/- 2.2884e-04 (0.37%) (init = 0.13)\n",
        "[[Correlations]] (unreported correlations are < 0.100)\n",
        "    C(b, a) = +0.6938"
      ],
      "metadata": {
        "id": "SctlkdQ-6CWN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the code loads fitted parameters, experimental and modeled subespectra in CSV formatted files. One final cell, allows to identify the phases from an own database. The ML algorithm employed to guess the present phases is based on a K-Nearest Neighbors."
      ],
      "metadata": {
        "id": "aLZlamrq6CWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'Ancho(mm/s)': results_df.loc[results_df['Parameter'].isin(['d1_gamma', 'd2_gamma']), 'Value'].values.tolist(),\n",
        "    'IS (mm/s)': results_df.loc[results_df['Parameter'].isin(['d1_delta', 'd2_delta']), 'Value'].values.tolist(),\n",
        "    'Quad Splitting (mm/s)': results_df.loc[results_df['Parameter'].isin(['d1_quad', 'd2_quad']), 'Value'].values.tolist(),\n",
        "    'Bhf (T)': [0, 0]  # Ensure 'Bhf (T)' has the same length as others\n",
        "})\n",
        "df.to_csv(f\"{full}/{file}-report.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "3j7jwH-a6CWa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# 1. Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Cargar datos de referencia (base de datos)\n",
        "reference_path = '/content/drive/MyDrive/Colab-Notebooks/reference_data.csv'  # ¡Ajusta la ruta!\n",
        "df_ref = pd.read_csv(reference_path)\n",
        "\n",
        "# Función para convertir rangos a valores medios (ej: \"0.37-0.45\" → 0.41)\n",
        "def parse_value(value):\n",
        "    if isinstance(value, str) and '-' in value:\n",
        "        min_val, max_val = map(float, value.split('-'))\n",
        "        return (min_val + max_val) / 2\n",
        "    return float(value)\n",
        "\n",
        "# Procesar columnas relevantes\n",
        "cols = ['IS (mm/s)', 'Quad Splitting (mm/s)', 'Bhf (T)']\n",
        "for col in cols:\n",
        "    df_ref[col] = df_ref[col].apply(parse_value)\n",
        "\n",
        "# 3. Cargar datos experimentales\n",
        "experimental_path = f\"{full}/{file}-report.csv\"  # ¡Ajusta la ruta!\n",
        "df_exp = pd.read_csv(experimental_path)\n",
        "\n",
        "# 4. Preprocesar datos experimentales (manejar NaN)\n",
        "X_exp = df_exp[cols].fillna(0).values  # Si Bhf no existe, reemplazar NaN por 0\n",
        "\n",
        "# 5. Entrenar modelo KNN\n",
        "X_ref = df_ref[cols].values\n",
        "model = NearestNeighbors(n_neighbors=3, metric='euclidean')\n",
        "model.fit(X_ref)\n",
        "\n",
        "# 6. Encontrar coincidencias\n",
        "distances, indices = model.kneighbors(X_exp)\n",
        "\n",
        "# 7. Mostrar resultados\n",
        "for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
        "    print(f\"\\nMuestra experimental {i+1}:\")\n",
        "    for j, (d, pos) in enumerate(zip(dist, idx)):\n",
        "        compound = df_ref.iloc[pos]['Compound Name']\n",
        "        formula = df_ref.iloc[pos]['Chemical Formula']\n",
        "        is_ref = df_ref.iloc[pos]['IS (mm/s)']\n",
        "        qs_ref = df_ref.iloc[pos]['Quad Splitting (mm/s)']\n",
        "        bhf_ref = df_ref.iloc[pos]['Bhf (T)']\n",
        "        print(f\"  Match {j+1}: {compound} ({formula})\")\n",
        "        print(f\"    IS: {is_ref:.2f} mm/s | QS: {qs_ref:.2f} mm/s | Bhf: {bhf_ref:.1f} T\")\n",
        "        print(f\"    Distancia euclidiana: {d:.2f}\\n\")\n",
        "\n",
        "print(\"## Usar este resultado a modo orientativo. Se recomienda contar con información de la muestra en su composición y estructura ##\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "y5YCEqpn6CWe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
        "\n",
        "Muestra experimental 1:\n",
        "  Match 1: Condritas-Piroxeno ( (Mg;Fe)SiO₃)\n",
        "    IS: 1.17 mm/s | QS: 2.06 mm/s | Bhf: 0.0 T\n",
        "    Distancia euclidiana: 0.11\n",
        "\n",
        "  Match 2: Hemoglobina (deoxy) (Fe(C₃4H₃2N4O4))\n",
        "    IS: 0.95 mm/s | QS: 2.25 mm/s | Bhf: 0.0 T\n",
        "    Distancia euclidiana: 0.24\n",
        "\n",
        "  Match 3: Siderite (FeCO₃)\n",
        "    IS: 1.20 mm/s | QS: 1.90 mm/s | Bhf: 0.0 T\n",
        "    Distancia euclidiana: 0.28\n",
        "\n",
        "\n",
        "Muestra experimental 2:\n",
        "  Match 1: FeWO₄ (FeWO₄)\n",
        "    IS: 0.95 mm/s | QS: 1.65 mm/s | Bhf: 0.0 T\n",
        "    Distancia euclidiana: 0.45\n",
        "\n",
        "  Match 2: Hemoglobina (deoxy) (Fe(C₃4H₃2N4O4))\n",
        "    IS: 0.95 mm/s | QS: 2.25 mm/s | Bhf: 0.0 T\n",
        "    Distancia euclidiana: 0.50\n",
        "\n",
        "  Match 3: Nitroprusiato de sodio (Na₂[Fe(CN)₅NO])\n",
        "    IS: 0.10 mm/s | QS: 1.70 mm/s | Bhf: 0.0 T\n",
        "    Distancia euclidiana: 0.52\n",
        "\n",
        "## Usar este resultado a modo orientativo. Se recomienda contar con información de la muestra en su composición y estructura ##"
      ],
      "metadata": {
        "id": "HPBFKopX6CWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Examples\n",
        "\n",
        "Mössbauer spectrum of a comercial $LiFePO_{4}$ active material for batteries. Residual phases were detected, such as $FePO_{4}$ and $Fe_{2}P$. This last phase, shows the presence of $^{57}Fe$ in two diferent oxidation states, *Fe(I)* and *Fe(II)*, respectively.\n",
        "\n",
        "![image.png](attachment:5648c966-6a32-4bd0-91ba-0a8b05a3a567.png)\n",
        "\n",
        "Mössbauer spectrum of the $LiFePO_{4}$ active material for batteries, after synthesis at lab scale. In this case, just $LiFePO_{4}$ was detected, besides the extraordinary sensitivity of the\n",
        "characterization technique.\n",
        "\n",
        "![image.png](attachment:d26c793e-eaec-468b-ba77-04b8ffa4eb2f.png)\n",
        "\n",
        "CEMS spectrum of pyroxene in Mars soil (Opportunity Mission, Sept. 2004, T= 240-260K) [[Morris2006]](https://doi.org/10.1029/2006JE002791). The subespectra correspond to two different $^{57}Fe$ sites, M1 and M2, tipically found in pyroxene. [[Oshtrakh2007]](https://doi.org/10.1007/s10751-008-9646-4)\n",
        "\n",
        "![imagen.png](attachment:9a89fd2c-4cd5-43ef-9625-4d71a793bbcf.png)\n",
        "\n",
        "\n",
        "$^{57}Fe$ Mössbauer spectra of an Iguazú falls soil sample (Argentina-Brazil border)\n",
        "\n",
        "![image.png](attachment:960c373a-2e1f-4a76-b5fb-896837f89ee3.png)\n",
        "\n",
        "# References\n",
        "[Mossbauer_Wikipedia] *Mössbauer Spectroscopy*, http://en.m.wikipedia.org/wiki/Mössbauer_spectroscopy\n",
        "\n",
        "[Grandjean2021] Grandjean, F. and Long, G. J., *Best Practices and Protocols in Mössbauer Spectroscopy*,Chem. Mater. 2021, 33, 3878−3904\n",
        "\n",
        "[Saccone2024a] Saccone, F. D., Release of *PyMossFit* in Github, https://github.com/fsacconeUBA/Mossbauer/releases/tag/PyMossFit-V6\n",
        "\n",
        "[Saccone2024b] Saccone, F.D., *PyMossFit*, ResearchGate, http://dx.doi.org/10.13140/RG.2.2.20717.81127\n",
        "\n",
        "[Kong2020] Kong, Q; Siauw, T. and Bayen, A., *Python Programming and Numerical Methods - A Guide for Engineers and Scientists*, https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/Index.html\n",
        "\n",
        "[Ferrari2015] Ferrari, S. et al, *Structural and magnetic properties of Zn doped magnetite nanoparticles obtained by wet chemical method*, IEEE Transactions on Magnetics, vol. 51, no. 6, pp. 1-6, June 2015, Art no. 2900206\n",
        "\n",
        "[Morris2006] Morris, R. V., et al. (2006), *Mösbauer mineralogy of rock, soil, and dust at Meridiani Planum, Mars: Opportunity’s\n",
        "journey across sulfate-rich outcrop, basaltic sand and dust, and hematite lag deposits*, J. Geophys. Res., 111, E12S15,\n",
        "\n",
        "[Oshtrakh2007] Oshtrakh, M. I., *Determination of quadrupole splitting for 57Fe in M1\n",
        "and M2 sites of both olivine and pyroxene in ordinary\n",
        "chondrites using Mössbauer spectroscopy with high\n",
        "velocity resolution*, Hyperfine Interact (2007) 177, pp. 65-71"
      ],
      "metadata": {
        "id": "xg8kukMf6CWk"
      }
    }
  ]
}