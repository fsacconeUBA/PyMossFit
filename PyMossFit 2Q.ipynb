{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tS5n1PxK7rL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Folding by FFT and smoothing with Savizky-Golay (this last, just for poor statistics spectra). Fitting by lmfit library.\n",
        "Likewise, it is included an option to identify phases by K-Nearest Neighbors (KNN) from hyperfine parameters results comparison with a local database\n",
        "The next lines prepare Drive connection and import necessary libraries\n",
        "\"\"\"\n",
        "!pip install lmfit\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount= True)\n",
        "img = '/content/drive/MyDrive/Colab\\ Notebooks/PyMossFit/My File'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from lmfit import Parameters, minimize, fit_report, Model\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.constants import *\n",
        "from scipy.integrate import trapezoid\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.stats import norm\n",
        "from pathlib import Path\n",
        "\n",
        "path= Path(img); file= path.stem; title= path.parent.name; full= path.parents[0]; print(file, title, full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7iOaAYD2-fr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Loud and folding raw datafile subsection\n",
        "\"\"\"\n",
        "y= np.loadtxt(img, skiprows=0); #y=y[:,1] #add delivery=\" \" or delimiter=\" \" in load txt if your file includes 2 columns. Instead, comments y=y[:,1]\n",
        "N=len(y); N2=int(N/2); N4=int(N/4)\n",
        "\n",
        "fecha = str(input('Ingrese la fecha de calibración (AAAAMMDD): '),)\n",
        "vel = float(input('Ingrese el rango de V (en mm/s): ' ), )\n",
        "np.savetxt(f\"{full}/{file}-calib.txt\", (fecha,vel, N), fmt='%s')\n",
        "\n",
        "#y= savgol_filter(y, 5, 2) #Just if the spectrum has poor statistic. Instead, comments it\n",
        "plt.plot(y)\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "Folding by FFT (based on Nyquist-Shannon sampling theorem, https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.02-Discrete-Fourier-Transform.html)\n",
        "\"\"\"\n",
        "f= abs(np.fft.fft(y)); Nf=pd.Series(f[N2-5:N2+5]).idxmax()+(N2-5)\n",
        "plt.plot(f[1:N])\n",
        "plt.show()\n",
        "\n",
        "for i in range(0, Nf-1):\n",
        "    y[[i]]=y[[i]]+y[[N-1-i]]\n",
        "\n",
        "y=y[0:N2-1]\n",
        "\n",
        "\"\"\"\n",
        "Normalization\n",
        "\"\"\"\n",
        "y2= np.concatenate([y[2:30],y[N2-30:N2-2]])\n",
        "\n",
        "ymax=np.mean(y2)\n",
        "ymax=int(ymax)\n",
        "\n",
        "for i in range(0, N2-1):\n",
        "    y[[i]]=y[[i]]/ymax\n",
        "\n",
        "x=np.arange(1,N2)\n",
        "\n",
        "\"\"\"\n",
        "From channels to mm/s\n",
        "\"\"\"\n",
        "v=np.loadtxt(f\"{full}/{file}-calib.txt\"); vmax=v[[1]]\n",
        "\n",
        "x=np.linspace(start = 0, stop = N2-1, num= N2)\n",
        "\n",
        "for i in range(0, N2-1):\n",
        "    x[[i]]=(i-N4)*vmax/N4\n",
        "\n",
        "x= x[0:N2-1]\n",
        "\n",
        "print('Mean Background:', ymax); print('Folding channel:', Nf)\n",
        "\n",
        "plt.plot(x,y, marker=\"o\")\n",
        "plt.show()\n",
        "\n",
        "np.savetxt(f\"{full}/{file}.csv\", list(zip(x,y)), delimiter=\",\", fmt='%1.6f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6YWn_7DolT2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Reading folded datafile\n",
        "\"\"\"\n",
        "col_list=[0, 1]\n",
        "\n",
        "x, y= np.loadtxt(f\"{full}/{file}.csv\", delimiter=\",\", usecols=col_list, unpack=True)\n",
        "\n",
        "\"\"\"\n",
        "Functions definition for fitting, based in lorentzian shapes\n",
        "\"\"\"\n",
        "# Mössbauer constants for doublet (transition level factors)\n",
        "positions_d = np.array([-1 , 1]) / 2  # Relatives to quadrupolar splitting\n",
        "intensities_d = np.array([1, 1])  # Relatives to line intensities\n",
        "\n",
        "# Mössbauer constants for sextets (transition level factors)\n",
        "positions_x = np.array([-3., -1.7, -0.5, 0.5, 1.7, 3.]) / 2  # Relatives to hyperfine Field\n",
        "intensities_x = np.array([1, 2, 1., 1., 2, 1])  # Relatives to line intensities\n",
        "\n",
        "def lorentzian(x, amplitude, center, width):\n",
        "    \"\"\"Singlet Lorentzian Function\"\"\"\n",
        "    return amplitude * (2*width / ((np.pi) * ((x - center)**2 + width**2)))\n",
        "\n",
        "def doublet_lorentzian(x, delta, quad, gamma, scale):\n",
        "    \"\"\"\n",
        "    Doublet model for Mössbauer spectrum of quadrupolar splitting.\n",
        "\n",
        "    Parameters:\n",
        "    - delta: Isomer Shift (IS)\n",
        "    - quad: Quadrupolar Splitting (QS)\n",
        "    - gamma: Lorentzian function linewidth\n",
        "    - scale: intensity scale factor\n",
        "    \"\"\"\n",
        "    y = np.zeros_like(x)\n",
        "    for i, (pos, inten) in enumerate(zip(positions_d, intensities_d)):\n",
        "        center = delta + pos * quad\n",
        "        y += lorentzian(x, scale * inten, center, gamma)\n",
        "    return y\n",
        "\n",
        "def sextet_lorentzian(x, delta, B_hf, gamma, scale):\n",
        "    \"\"\"\n",
        "    Sextet model for Mössbauer spectrum of Zeeman splitting..\n",
        "\n",
        "    Parámetros:\n",
        "    - delta: Isomer shift (IS)\n",
        "    - B_hf: hyperfine magnetic field\n",
        "    - gamma: Lorentzian function linewidth\n",
        "    - scale: intensity scale factor\n",
        "    \"\"\"\n",
        "    y = np.zeros_like(x)\n",
        "    for i, (pos, inten) in enumerate(zip(positions_x, intensities_x)):\n",
        "        center = delta + pos * B_hf\n",
        "        y += lorentzian(x, scale * inten, center, gamma)\n",
        "    return y\n",
        "\n",
        "# Lmfit for model definition and fitting\n",
        "from lmfit import Model, minimize, fit_report\n",
        "doublet1 = Model(doublet_lorentzian, prefix= 'd1_')\n",
        "doublet2 = Model(doublet_lorentzian, prefix= 'd2_')\n",
        "combined_model= doublet1 + doublet2\n",
        "\n",
        "# Configuration of initial parameters and their limits\n",
        "params = combined_model.make_params(d1_delta=1.1, d1_quad=2.9, d1_gamma=0.35, d1_scale=0.2, d2_delta=0.4, d2_quad=0.4, d2_gamma=0.35, d2_scale=0.2)\n",
        "params['d1_delta'].set(min=-0.7, max=1.5)       # Ejemplo de límite para delta\n",
        "params['d1_quad'].set(min=0, max=3.5)        # Límite para desdoblamiento cuadrupolar\n",
        "params['d1_gamma'].set(min=0.0, max=0.45)      # Límite para ancho de línea\n",
        "params['d1_scale'].set(min=0.0, max=1)      # Límite para escala de intensidad\n",
        "\n",
        "params['d2_delta'].set(min=-0.7, max=1.5)       # Ejemplo de límite para delta\n",
        "params['d2_quad'].set(min=0, max=0.95)        # Límite para desdoblamiento cuadrupolar\n",
        "params['d2_gamma'].set(min=0.0, max=0.35)      # Límite para ancho de línea\n",
        "params['d2_scale'].set(min=0.0, max=1)      # Límite para escala de intensidad\n",
        "\n",
        "def linear_fitting_lmfit(params, x, y):\n",
        "    y_fit= 1-combined_model.eval(params=params, x=x)\n",
        "\n",
        "    return y_fit-y\n",
        "\n",
        "# Results extraction and their saving in a DataFrame\n",
        "param_headers = []\n",
        "param_values = []\n",
        "param_errors = []\n",
        "\n",
        "# Fitting with a linear regression model\n",
        "result = minimize(linear_fitting_lmfit, params, args=(x,y), method='least_squares')\n",
        "best_fit= 1-combined_model.eval(params=result.params, x=x)\n",
        "\n",
        "doublet1_fit= doublet1.eval(params=result.params, x=x)\n",
        "doublet2_fit= doublet2.eval(params=result.params, x=x)\n",
        "\n",
        "for name, param in result.params.items():\n",
        "      param_headers.append(name)\n",
        "      param_values.append(param.value)\n",
        "      param_errors.append(param.stderr)\n",
        "\n",
        "#Subespectral area are calculated as: i= trapz(1-z, x); i1= trapz(1-z1, x)/i*100; i2=trapz(1-z2, x)/i*100; etc con z=z1+z2+...\n",
        "i = trapezoid(doublet1_fit + doublet2_fit, x)\n",
        "i1 = trapezoid(doublet1_fit, x)/i*100\n",
        "i2 = trapezoid(doublet2_fit, x)/i*100\n",
        "\n",
        "e= (y-best_fit)/y*100\n",
        "\n",
        "# Results printing\n",
        "print(fit_report(result))\n",
        "\n",
        "\"\"\"\n",
        "PLOTS OF ESPECTRA AND SUBESPECTRA\n",
        "\"\"\"\n",
        "plt.style.use('bmh')\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, sharex=True, height_ratios=[1,3.5]); fig.suptitle(f\"{title}\" \" - \" f\"{file}\")\n",
        "ax1.scatter (x, e, c= 'black', marker= '+')\n",
        "ax1.set_ylim(-1.5,1.5)\n",
        "ax1.set_ylabel('Error (%)'); #plt.axis('tight')\n",
        "\n",
        "ax2.scatter (x, y, c= 'black', marker= '+')\n",
        "ax2.set_xlabel('V(mm/s)')\n",
        "ax2.set_ylabel('Relative Transmission(a.u.)')\n",
        "ax2.plot(x, best_fit, c='red')\n",
        "ax2.plot(x, 1-doublet1_fit, c='blue', label= 'QS 1')\n",
        "ax2.plot(x, 1-doublet2_fit, c='green', label= 'QS 2')\n",
        "ax2.legend(handlelength=4, loc='lower left', shadow=True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "OUTPUT DATAFILE GENERATION: DATA Y PARAMETERS\n",
        "\"\"\"\n",
        "np.savetxt(f\"{full}/{file}-plot.csv\", list(zip(x, y, doublet1_fit, doublet2_fit, best_fit)), delimiter=',', fmt='%1.6e') #\n",
        "\n",
        "# DataFrame Creation\n",
        "results_df = pd.DataFrame({\n",
        "    'Parameter': param_headers,\n",
        "    'Value': param_values,\n",
        "    'Error': param_errors\n",
        "})\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Ancho(mm/s)': results_df.loc[results_df['Parameter'].isin(['d1_gamma', 'd2_gamma']), 'Value'].values.tolist(),\n",
        "    'IS (mm/s)': results_df.loc[results_df['Parameter'].isin(['d1_delta', 'd2_delta']), 'Value'].values.tolist(),\n",
        "    'Quad Splitting (mm/s)': results_df.loc[results_df['Parameter'].isin(['d1_quad', 'd2_quad']), 'Value'].values.tolist(),\n",
        "    'Bhf (T)': [0, 0], 'Áreas (%)': [i1, i2] # Ensure 'Bhf (T)' has the same length as others\n",
        "})\n",
        "\n",
        "#df= df.apply(lambda x: round (x,1))\n",
        "df.to_csv(f\"{full}/{file}-report.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "KNN algorithm for potential phases identification\n",
        "\"\"\"\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# 1. Google Drive Mounting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Louding reference data  (Database)\n",
        "reference_path = '/content/drive/MyDrive/Colab\\ Notebooks/PyMossFit/reference_data.csv'  # Reference data path\n",
        "df_ref = pd.read_csv(reference_path)\n",
        "\n",
        "# Function for mean range definition (i.e..: \"0.37-0.45\" → 0.41)\n",
        "def parse_value(value):\n",
        "    if isinstance(value, str) and '-' in value:\n",
        "        min_val, max_val = map(float, value.split('-'))\n",
        "        return (min_val + max_val) / 2\n",
        "    return float(value)\n",
        "\n",
        "# Relevant columns processing\n",
        "cols = ['IS (mm/s)', 'Quad Splitting (mm/s)', 'Bhf (T)']\n",
        "for col in cols:\n",
        "    df_ref[col] = df_ref[col].apply(parse_value)\n",
        "\n",
        "# 3. Louding experimental data\n",
        "experimental_path = f\"{full}/{file}-report.csv\"  # ¡Ajusta la ruta!\n",
        "df_exp = pd.read_csv(experimental_path)\n",
        "\n",
        "# 4. Pre-processing of experimental data (management of NaN)\n",
        "X_exp = df_exp[cols].fillna(0).values  # Si Bhf no existe, reemplazar NaN por 0\n",
        "\n",
        "# 5. KNN Model Training\n",
        "X_ref = df_ref[cols].values\n",
        "model = NearestNeighbors(n_neighbors=3, metric='euclidean')\n",
        "model.fit(X_ref)\n",
        "\n",
        "# 6. Matching coincidences\n",
        "distances, indices = model.kneighbors(X_exp)\n",
        "\n",
        "# 7. Showing results\n",
        "for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
        "    print(f\"\\nMuestra experimental {i+1}:\")\n",
        "    for j, (d, pos) in enumerate(zip(dist, idx)):\n",
        "        compound = df_ref.iloc[pos]['Compound Name']\n",
        "        formula = df_ref.iloc[pos]['Chemical Formula']\n",
        "        is_ref = df_ref.iloc[pos]['IS (mm/s)']\n",
        "        qs_ref = df_ref.iloc[pos]['Quad Splitting (mm/s)']\n",
        "        bhf_ref = df_ref.iloc[pos]['Bhf (T)']\n",
        "        print(f\"  Match {j+1}: {compound} ({formula})\")\n",
        "        print(f\"    IS: {is_ref:.2f} mm/s | QS: {qs_ref:.2f} mm/s | Bhf: {bhf_ref:.1f} T\")\n",
        "        print(f\"    Distancia euclidiana: {d:.2f}\\n\")\n",
        "\n",
        "print(\"## Use this result in an orientative way. It is recomended to complement it with compositional and structural  information of the samples ##\")"
      ],
      "metadata": {
        "id": "tJIvF09MobnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}